{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import utils\n",
    "from utils import ImagePair, ImageMatcher\n",
    "import h5py\n",
    "from scipy.spatial.transform import Rotation as Rot\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "# Load a pre-trained DeepLabV3 model\n",
    "model = models.segmentation.deeplabv3_resnet101(\n",
    "    weights=models.segmentation.DeepLabV3_ResNet101_Weights.DEFAULT\n",
    ").eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_frames_in_batches(frames, batch_size, device):\n",
    "    num_frames = len(frames)\n",
    "    human_segmentation_masks = []\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "    for i in range(0, num_frames, batch_size):\n",
    "        # Get the batch of frames\n",
    "        batch_frames = frames[i:i + batch_size]\n",
    "\n",
    "        # Apply transformation and stack frames into a batch\n",
    "        batch = torch.stack([transform(frame) for frame in batch_frames]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch)['out']\n",
    "\n",
    "        # Get the segmentation masks for the human class and move them back to the CPU\n",
    "        batch_masks = [(output.argmax(0) == 15).cpu().numpy() for output in outputs]\n",
    "        human_segmentation_masks.extend(batch_masks)\n",
    "\n",
    "    return np.array(human_segmentation_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/richard/Desktop/TestDataset/'\n",
    "vid_paths = glob(DATA_DIR + '*.mp4')\n",
    "\n",
    "for i, vid_path in enumerate(vid_paths, start=1):\n",
    "    print(f'({i}/{len(vid_paths)}) {vid_path}...')\n",
    "    frames = utils.load_video(vid_path, grayscale=False)\n",
    "    masks = segment_frames_in_batches(frames, batch_size=8, device=device)\n",
    "\n",
    "    # Save the masks as compressed npz\n",
    "    out_path = vid_path.replace('.mp4', '-masks.npz')\n",
    "    np.savez_compressed(out_path, masks=masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
